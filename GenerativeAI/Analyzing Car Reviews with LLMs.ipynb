{"cells":[{"source":"![image](car.jpeg)\n\n**Car-ing is sharing**, an auto dealership company for car sales and rental, is taking their services to the next level thanks to **Large Language Models (LLMs)**.\n\nAs their newly recruited AI and NLP developer, you've been asked to prototype a chatbot app with multiple functionalities that not only assist customers but also provide support to human agents in the company.\n\nThe solution should receive textual prompts and use a variety of pre-trained Hugging Face LLMs to respond to a series of tasks, e.g. classifying the sentiment in a carâ€™s text review, answering a customer question, summarizing or translating text, etc.\n","metadata":{},"id":"9aabafca-8129-4943-b865-d5e897637253","cell_type":"markdown"},{"source":"# Import necessary packages\nimport pandas as pd\nimport torch\n\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)\n","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1748472564971,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary packages\nimport pandas as pd\nimport torch\n\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)\n","outputsMetadata":{"0":{"height":437,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedByKernel":"146df8a2-e575-4c6d-8a3a-615568e14a7c"},"id":"5325a4c0-ceb3-4b66-acd2-5eadcefe3a63","cell_type":"code","execution_count":5,"outputs":[]},{"source":"# Start your code here!\npath = \"data/car_reviews.csv\"\ndf = pd.read_csv(path, delimiter=\";\")\n\nreviews = df['Review'].tolist()\nclasses = df['Class'].tolist()\n\nfrom transformers import pipeline\nclassifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\npredicted_labels = classifier(reviews)\nprint(predicted_labels)\n\nimport evaluate\naccuracy = evaluate.load(\"accuracy\")\nf1 = evaluate.load(\"f1\")\n\nreferences = [1 if label == \"POSITIVE\" else 0 for label in classes]\npredictions = [1 if label['label'] == \"POSITIVE\" else 0 for label in predicted_labels]\n\naccuracy_result_dict = accuracy.compute(references=references, predictions=predictions)\naccuracy_result = accuracy_result_dict['accuracy']\nf1_result_dict = f1.compute(references=references, predictions=predictions)\nf1_result = f1_result_dict['f1']\nprint(f\"Accuracy: {accuracy_result}\")\nprint(f\"F1 result: {f1_result}\")\n\n################################################# 2 #######################################################\n\nfirst_review = reviews[0]\nsentences = first_review.split('.')\nfirst_two_sentences = '.'.join(sentences[:2]).strip() + '.'\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\ntranslated_review = translator(first_two_sentences)[0]['translation_text']\nprint(f\"Model translation:\\n{translated_review}\")\n\nwith open(\"data/reference_translations.txt\", 'r') as file:\n    lines = file.readlines()\nreferences = [line.strip() for line in lines]\nprint(f\"Spanish translation references:\\n{references}\")\n\nbleu = evaluate.load(\"bleu\")\nbleu_score = bleu.compute(predictions=[translated_review], references=[references])\nprint(bleu_score['bleu'])\n\n################################################# 3 #######################################################\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForQuestionAnswering\nqa_model = \"deepset/minilm-uncased-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(qa_model)\nmodel = AutoModelForQuestionAnswering.from_pretrained(qa_model)\n\ncontext = reviews[1]\nquestion = \"What did he like about the brand?\"\ninputs = tokenizer(question, context, return_tensors=\"pt\")\n\nwith torch.no_grad():\n  outputs = model(**inputs)\nstart_idx = torch.argmax(outputs.start_logits)\nend_idx = torch.argmax(outputs.end_logits) + 1\nanswer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n\nanswer = tokenizer.decode(answer_span)\nprint(\"Extractive QA answer:\", answer)\n################################################# 4 #######################################################\n\n# Get original text to summarize upon car review\ntext_to_summarize = reviews[-1]\nprint(f\"Original text:\\n{text_to_summarize}\")\n\n# Load summarization pipeline and perform inference\nmodel_name = \"cnicu/t5-small-booksum\"\nsummarizer = pipeline(\"summarization\", model=model_name)\noutputs = summarizer(text_to_summarize, max_length=53)\nsummarized_text = outputs[0]['summary_text']\nprint(f\"Summarized text:\\n{summarized_text}\")","metadata":{"executionCancelledAt":null,"executionTime":8723,"lastExecutedAt":1748472573695,"lastExecutedByKernel":"146df8a2-e575-4c6d-8a3a-615568e14a7c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start your code here!\npath = \"data/car_reviews.csv\"\ndf = pd.read_csv(path, delimiter=\";\")\n\nreviews = df['Review'].tolist()\nclasses = df['Class'].tolist()\n\nfrom transformers import pipeline\nclassifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\npredicted_labels = classifier(reviews)\nprint(predicted_labels)\n\nimport evaluate\naccuracy = evaluate.load(\"accuracy\")\nf1 = evaluate.load(\"f1\")\n\nreferences = [1 if label == \"POSITIVE\" else 0 for label in classes]\npredictions = [1 if label['label'] == \"POSITIVE\" else 0 for label in predicted_labels]\n\naccuracy_result_dict = accuracy.compute(references=references, predictions=predictions)\naccuracy_result = accuracy_result_dict['accuracy']\nf1_result_dict = f1.compute(references=references, predictions=predictions)\nf1_result = f1_result_dict['f1']\nprint(f\"Accuracy: {accuracy_result}\")\nprint(f\"F1 result: {f1_result}\")\n\n################################################# 2 #######################################################\n\nfirst_review = reviews[0]\nsentences = first_review.split('.')\nfirst_two_sentences = '.'.join(sentences[:2]).strip() + '.'\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\ntranslated_review = translator(first_two_sentences)[0]['translation_text']\nprint(f\"Model translation:\\n{translated_review}\")\n\nwith open(\"data/reference_translations.txt\", 'r') as file:\n    lines = file.readlines()\nreferences = [line.strip() for line in lines]\nprint(f\"Spanish translation references:\\n{references}\")\n\nbleu = evaluate.load(\"bleu\")\nbleu_score = bleu.compute(predictions=[translated_review], references=[references])\nprint(bleu_score['bleu'])\n\n################################################# 3 #######################################################\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForQuestionAnswering\nqa_model = \"deepset/minilm-uncased-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(qa_model)\nmodel = AutoModelForQuestionAnswering.from_pretrained(qa_model)\n\ncontext = reviews[1]\nquestion = \"What did he like about the brand?\"\ninputs = tokenizer(question, context, return_tensors=\"pt\")\n\nwith torch.no_grad():\n  outputs = model(**inputs)\nstart_idx = torch.argmax(outputs.start_logits)\nend_idx = torch.argmax(outputs.end_logits) + 1\nanswer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n\nanswer = tokenizer.decode(answer_span)\nprint(\"Extractive QA answer:\", answer)\n################################################# 4 #######################################################\n\n# Get original text to summarize upon car review\ntext_to_summarize = reviews[-1]\nprint(f\"Original text:\\n{text_to_summarize}\")\n\n# Load summarization pipeline and perform inference\nmodel_name = \"cnicu/t5-small-booksum\"\nsummarizer = pipeline(\"summarization\", model=model_name)\noutputs = summarizer(text_to_summarize, max_length=53)\nsummarized_text = outputs[0]['summary_text']\nprint(f\"Summarized text:\\n{summarized_text}\")","outputsMetadata":{"0":{"height":38,"type":"stream"},"1":{"height":122,"type":"stream"},"4":{"height":38,"type":"stream"},"5":{"height":80,"type":"stream"},"10":{"height":38,"type":"stream"},"11":{"height":164,"type":"stream"},"15":{"height":38,"type":"stream"},"21":{"height":185,"type":"stream"},"22":{"height":290,"type":"stream"},"30":{"height":38,"type":"stream"}}},"id":"6c3a3bf7-8675-4fdf-8580-0c69b58f471e","cell_type":"code","execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"},{"output_type":"stream","name":"stdout","text":"[{'label': 'POSITIVE', 'score': 0.929397702217102}, {'label': 'POSITIVE', 'score': 0.8654273152351379}, {'label': 'POSITIVE', 'score': 0.9994640946388245}, {'label': 'NEGATIVE', 'score': 0.9935314059257507}, {'label': 'POSITIVE', 'score': 0.9986565113067627}]\nAccuracy: 0.8\nF1 result: 0.8571428571428571\n"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f0406faf4a64c7fb99d647b474c7bd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbfeac1282364dc2817d5725e7cfd3bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e371f0b2f0443d4a15bbda5e7f26bb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7b0a5ef5c8040ccb1a4aacdfad221b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263f57742aa846beb19da12d2f308de8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc80c63852d4b2797571b72e6769126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/826k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7c177db9c34571ae0313b26b5d6fb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f3831d3ef3b465298898a9769d079e5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"},{"output_type":"stream","name":"stdout","text":"Model translation:\nEstoy muy satisfecho con mi Nissan NV SL 2014. Uso esta camioneta para mis entregas de negocios y uso personal.\nSpanish translation references:\n['Estoy muy satisfecho con mi Nissan NV SL 2014. Utilizo esta camioneta para mis entregas comerciales y uso personal.', 'Estoy muy satisfecho con mi Nissan NV SL 2014. Uso esta furgoneta para mis entregas comerciales y uso personal.']\n"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b8a68196dfd456395aaa0a5a568d9b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff609c71196949a7958c2c62ff888667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff1c2e56a9734423b3a5bf3e7e70d4ab"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"0.7794483794144497\n"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/107 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e29f659dfdcb4bb6b0a769ffe07beb24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803c7e77d80e455fb11bbbe1deab5846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4fcf98ef9334546a6ccce2dbda8e47f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"330a035bd33541f9a16a55a568dae13d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b851a54a990847c59da18f76c3ef449a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"},{"output_type":"stream","name":"stdout","text":"Extractive QA answer: ride quality, reliability\nOriginal text:\nI've been dreaming of owning an SUV for quite a while, but I've been driving cars that were already paid for during an extended period. I ultimately made the decision to transition to a brand-new car, which, of course, involved taking on new payments. However, given that I don't drive extensively, I was inclined to avoid a substantial financial commitment. The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. I am VERY satisfied overall. I find myself needing to exercise extra caution when making lane changes, particularly owing to the blind spots resulting from the small side windows situated towards the rear of the vehicle. To address this concern, I am actively engaged in making adjustments to my mirrors and consciously reducing the frequency of lane changes. The engine delivers strong performance, and the ride is really smooth.\n"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea1398afc1847ac8f852d068ee09663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86ad22750bec4ad2b02464e555391492"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6662f4ba6f684806a9c14cbc7d136a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbb04681c608479288b358f383456281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a66e804a3c74f3788836430c793c983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd2a802b222d4286a96992412f4a9d5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697ca26887374cafba37daba679c7095"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"},{"output_type":"stream","name":"stdout","text":"Summarized text:\nthe Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. I have hauled 12 bags of mulch in the back with the seats down and could have held more.\n"}]}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}