{"cells":[{"source":"","metadata":{"executionCancelledAt":null,"executionTime":1427,"lastExecutedAt":1743592936331,"lastExecutedByKernel":"72fd36e2-d745-4eb0-9775-6d6f4c7996e7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"cell_type":"code","id":"4b8fb0d4-fd77-4819-ae03-5aa92e5acc0f","outputs":[],"execution_count":0},{"source":"import pandas as pd\n\n# Load datasets\nauto_mpg = pd.read_parquet('auto-mpg.parquet')\nautos = pd.read_parquet('autos.parquet')\nhungarian_heart_disease = pd.read_parquet('hungarian-heart-disease.parquet')\n\n# Function to summarize dataset\n\ndef summarize_dataset(df):\n    row_count = df.shape[0]\n    col_count = df.shape[1]\n    missings_ratio = df.isna().sum().sum() / (row_count * col_count)\n    class_count = df['class'].nunique()\n    return row_count, col_count, missings_ratio, class_count\n\n# Summarize each dataset\nsummary_auto_mpg = summarize_dataset(auto_mpg)\nsummary_autos = summarize_dataset(autos)\nsummary_hungarian_heart_disease = summarize_dataset(hungarian_heart_disease)\n\n# Create summary table\ndataset_summary = pd.DataFrame({\n    'dataset': ['auto-mpg', 'autos', 'hungarian-heart-disease'],\n    'row_count': [summary_auto_mpg[0], summary_autos[0], summary_hungarian_heart_disease[0]],\n    'col_count': [summary_auto_mpg[1], summary_autos[1], summary_hungarian_heart_disease[1]],\n    'missings_ratio': [summary_auto_mpg[2], summary_autos[2], summary_hungarian_heart_disease[2]],\n    'class_count': [summary_auto_mpg[3], summary_autos[3], summary_hungarian_heart_disease[3]]\n})\n\ndataset_summary","metadata":{"executionCancelledAt":null,"executionTime":1954,"lastExecutedAt":1743592938286,"lastExecutedByKernel":"72fd36e2-d745-4eb0-9775-6d6f4c7996e7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n\n# Load datasets\nauto_mpg = pd.read_parquet('auto-mpg.parquet')\nautos = pd.read_parquet('autos.parquet')\nhungarian_heart_disease = pd.read_parquet('hungarian-heart-disease.parquet')\n\n# Function to summarize dataset\n\ndef summarize_dataset(df):\n    row_count = df.shape[0]\n    col_count = df.shape[1]\n    missings_ratio = df.isna().sum().sum() / (row_count * col_count)\n    class_count = df['class'].nunique()\n    return row_count, col_count, missings_ratio, class_count\n\n# Summarize each dataset\nsummary_auto_mpg = summarize_dataset(auto_mpg)\nsummary_autos = summarize_dataset(autos)\nsummary_hungarian_heart_disease = summarize_dataset(hungarian_heart_disease)\n\n# Create summary table\ndataset_summary = pd.DataFrame({\n    'dataset': ['auto-mpg', 'autos', 'hungarian-heart-disease'],\n    'row_count': [summary_auto_mpg[0], summary_autos[0], summary_hungarian_heart_disease[0]],\n    'col_count': [summary_auto_mpg[1], summary_autos[1], summary_hungarian_heart_disease[1]],\n    'missings_ratio': [summary_auto_mpg[2], summary_autos[2], summary_hungarian_heart_disease[2]],\n    'class_count': [summary_auto_mpg[3], summary_autos[3], summary_hungarian_heart_disease[3]]\n})\n\ndataset_summary","outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"312ebf8e-42db-488d-a8c0-f2b9cf094c6d","nodeType":"const"}}}}},"cell_type":"code","id":"745fd6ec-bd75-4c78-b607-3342e38e0d46","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"dataset","type":"string"},{"name":"row_count","type":"integer"},{"name":"col_count","type":"integer"},{"name":"missings_ratio","type":"number"},{"name":"class_count","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2],"dataset":["auto-mpg","autos","hungarian-heart-disease"],"row_count":[398,205,294],"col_count":[8,26,14],"missings_ratio":[0.0018844221,0.0110694184,0.1899902818],"class_count":[3,6,2]}},"total_rows":3,"truncation_type":null},"text/plain":"                   dataset  row_count  col_count  missings_ratio  class_count\n0                 auto-mpg        398          8        0.001884            3\n1                    autos        205         26        0.011069            6\n2  hungarian-heart-disease        294         14        0.189990            2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>row_count</th>\n      <th>col_count</th>\n      <th>missings_ratio</th>\n      <th>class_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>auto-mpg</td>\n      <td>398</td>\n      <td>8</td>\n      <td>0.001884</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autos</td>\n      <td>205</td>\n      <td>26</td>\n      <td>0.011069</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hungarian-heart-disease</td>\n      <td>294</td>\n      <td>14</td>\n      <td>0.189990</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":1}],"execution_count":1},{"source":"import numpy as np\n\nclass DecisionStumpClassifier:\n    def __init__(self):\n        self.feature_index = None\n        self.threshold = None\n        self.polarity = 1\n        self.alpha = None\n\n    def fit(self, X, y):\n        m, n = X.shape\n        self.alpha = 1\n        min_error = float('inf')\n\n        for feature_index in range(n):\n            feature_values = np.expand_dims(X[:, feature_index], axis=1)\n            unique_values = np.unique(feature_values)\n\n            for threshold in unique_values:\n                p = 1\n                predictions = np.ones(m)\n                predictions[X[:, feature_index] < threshold] = -1\n\n                error = sum(y != predictions)\n\n                if error > 0.5 * m:\n                    error = m - error\n                    p = -1\n\n                if error < min_error:\n                    self.polarity = p\n                    self.threshold = threshold\n                    self.feature_index = feature_index\n                    min_error = error\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        X_column = X[:, self.feature_index]\n        predictions = np.ones(n_samples)\n        if self.polarity == 1:\n            predictions[X_column < self.threshold] = -1\n        else:\n            predictions[X_column >= self.threshold] = -1\n        return predictions\n\n# Example usage\nX = np.array([[2, 3], [1, 1], [2, 1], [1, 2]])\ny = np.array([1, -1, 1, -1])\nstump = DecisionStumpClassifier()\nstump.fit(X, y)\npredictions = stump.predict(X)\nprint(predictions)","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1743593768187,"lastExecutedByKernel":"72fd36e2-d745-4eb0-9775-6d6f4c7996e7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\n\nclass DecisionStumpClassifier:\n    def __init__(self):\n        self.feature_index = None\n        self.threshold = None\n        self.polarity = 1\n        self.alpha = None\n\n    def fit(self, X, y):\n        m, n = X.shape\n        self.alpha = 1\n        min_error = float('inf')\n\n        for feature_index in range(n):\n            feature_values = np.expand_dims(X[:, feature_index], axis=1)\n            unique_values = np.unique(feature_values)\n\n            for threshold in unique_values:\n                p = 1\n                predictions = np.ones(m)\n                predictions[X[:, feature_index] < threshold] = -1\n\n                error = sum(y != predictions)\n\n                if error > 0.5 * m:\n                    error = m - error\n                    p = -1\n\n                if error < min_error:\n                    self.polarity = p\n                    self.threshold = threshold\n                    self.feature_index = feature_index\n                    min_error = error\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        X_column = X[:, self.feature_index]\n        predictions = np.ones(n_samples)\n        if self.polarity == 1:\n            predictions[X_column < self.threshold] = -1\n        else:\n            predictions[X_column >= self.threshold] = -1\n        return predictions\n\n# Example usage\n#X = np.array([[2, 3], [1, 1], [2, 1], [1, 2]])\n#y = np.array([1, -1, 1, -1])\nX = np.array([[1], [2], [3], [4], [5]])\ny = np.array([0, 0, 1, 1, 1]) \nstump = DecisionStumpClassifier()\nstump.fit(X, y)\npredictions = stump.predict(X)\nprint(predictions)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"a941799e-49d5-4e51-adf1-3cada19e1d24","outputs":[{"output_type":"stream","name":"stdout","text":"[ 1.  1.  1.  1. -1.]\n"}],"execution_count":10},{"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\nclass DecisionStumpClassifier:\n    def __init__(self):\n        self.feature_index = None\n        self.threshold = None\n        self.polarity = 1\n        self.alpha = None\n\n    def fit(self, X, y):\n        m, n = X.shape\n        self.alpha = 1\n        min_error = float('inf')\n\n        for feature_index in range(n):\n            feature_values = np.expand_dims(X[:, feature_index], axis=1)\n            unique_values = np.unique(feature_values)\n\n            for threshold in unique_values:\n                p = 1\n                predictions = np.ones(m)\n                predictions[X[:, feature_index] < threshold] = -1\n\n                error = sum(y != predictions)\n\n                if error > 0.5 * m:\n                    error = m - error\n                    p = -1\n\n                if error < min_error:\n                    self.polarity = p\n                    self.threshold = threshold\n                    self.feature_index = feature_index\n                    min_error = error\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        X_column = X[:, self.feature_index]\n        predictions = np.ones(n_samples)\n        if self.polarity == 1:\n            predictions[X_column < self.threshold] = -1\n        else:\n            predictions[X_column >= self.threshold] = -1\n        return predictions\n\n# Load datasets\nauto_mpg = pd.read_parquet('auto-mpg.parquet')\nautos = pd.read_parquet('autos.parquet')\nhungarian_heart_disease = pd.read_parquet('hungarian-heart-disease.parquet')\n\ndef evaluate_model(X, y, model):\n    skf = StratifiedKFold(n_splits=5)\n    scores = []\n    for train_index, test_index in skf.split(X, y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        scores.append(balanced_accuracy_score(y_test, y_pred))\n    return np.mean(scores)\n\n# Prepare datasets\nX_auto_mpg = auto_mpg.drop(columns=['class']).select_dtypes(include=[np.number]).values\ny_auto_mpg = auto_mpg['class'].astype(int).values\nX_autos = autos.drop(columns=['class']).select_dtypes(include=[np.number]).values\ny_autos = autos['class'].astype(int).values\nX_hungarian_heart_disease = hungarian_heart_disease.drop(columns=['class']).select_dtypes(include=[np.number]).values\ny_hungarian_heart_disease = hungarian_heart_disease['class'].astype(int).values\n\n# Evaluate models\nresults = {'dataset': ['auto-mpg', 'autos', 'hungarian-heart-disease'], 'DS': [], 'DT(max_depth=1)': [], 'DT': []}\n\nfor X, y, name in zip([X_auto_mpg, X_autos, X_hungarian_heart_disease], [y_auto_mpg, y_autos, y_hungarian_heart_disease], results['dataset']):\n    ds_model = DecisionStumpClassifier()\n    dt_model_depth_1 = DecisionTreeClassifier(max_depth=1)\n    dt_model = DecisionTreeClassifier()\n\n    ds_score = evaluate_model(X, y, ds_model)\n    dt_score_depth_1 = evaluate_model(X, y, dt_model_depth_1)\n    dt_score = evaluate_model(X, y, dt_model)\n\n    results['DS'].append(ds_score)\n    results['DT(max_depth=1)'].append(dt_score_depth_1)\n    results['DT'].append(dt_score)\n\nresults_df = pd.DataFrame(results)\nresults_df","metadata":{"executionCancelledAt":null,"executionTime":383,"lastExecutedAt":1743594922071,"lastExecutedByKernel":"72fd36e2-d745-4eb0-9775-6d6f4c7996e7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\nclass DecisionStumpClassifier:\n    def __init__(self):\n        self.feature_index = None\n        self.threshold = None\n        self.polarity = 1\n        self.alpha = None\n\n    def fit(self, X, y):\n        m, n = X.shape\n        self.alpha = 1\n        min_error = float('inf')\n\n        for feature_index in range(n):\n            feature_values = np.expand_dims(X[:, feature_index], axis=1)\n            unique_values = np.unique(feature_values)\n\n            for threshold in unique_values:\n                p = 1\n                predictions = np.ones(m)\n                predictions[X[:, feature_index] < threshold] = -1\n\n                error = sum(y != predictions)\n\n                if error > 0.5 * m:\n                    error = m - error\n                    p = -1\n\n                if error < min_error:\n                    self.polarity = p\n                    self.threshold = threshold\n                    self.feature_index = feature_index\n                    min_error = error\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        X_column = X[:, self.feature_index]\n        predictions = np.ones(n_samples)\n        if self.polarity == 1:\n            predictions[X_column < self.threshold] = -1\n        else:\n            predictions[X_column >= self.threshold] = -1\n        return predictions\n\n# Load datasets\nauto_mpg = pd.read_parquet('auto-mpg.parquet')\nautos = pd.read_parquet('autos.parquet')\nhungarian_heart_disease = pd.read_parquet('hungarian-heart-disease.parquet')\n\ndef evaluate_model(X, y, model):\n    skf = StratifiedKFold(n_splits=5)\n    scores = []\n    for train_index, test_index in skf.split(X, y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        scores.append(balanced_accuracy_score(y_test, y_pred))\n    return np.mean(scores)\n\n# Prepare datasets\nX_auto_mpg = auto_mpg.drop(columns=['class']).select_dtypes(include=[np.number]).values\ny_auto_mpg = auto_mpg['class'].astype(int).values\nX_autos = autos.drop(columns=['class']).select_dtypes(include=[np.number]).values\ny_autos = autos['class'].astype(int).values\nX_hungarian_heart_disease = hungarian_heart_disease.drop(columns=['class']).select_dtypes(include=[np.number]).values\ny_hungarian_heart_disease = hungarian_heart_disease['class'].astype(int).values\n\n# Evaluate models\nresults = {'dataset': ['auto-mpg', 'autos', 'hungarian-heart-disease'], 'DS': [], 'DT(max_depth=1)': [], 'DT': []}\n\nfor X, y, name in zip([X_auto_mpg, X_autos, X_hungarian_heart_disease], [y_auto_mpg, y_autos, y_hungarian_heart_disease], results['dataset']):\n    ds_model = DecisionStumpClassifier()\n    dt_model_depth_1 = DecisionTreeClassifier(max_depth=1)\n    dt_model = DecisionTreeClassifier()\n\n    ds_score = evaluate_model(X, y, ds_model)\n    dt_score_depth_1 = evaluate_model(X, y, dt_model_depth_1)\n    dt_score = evaluate_model(X, y, dt_model)\n\n    results['DS'].append(ds_score)\n    results['DT(max_depth=1)'].append(dt_score_depth_1)\n    results['DT'].append(dt_score)\n\nresults_df = pd.DataFrame(results)\nresults_df","outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"feae0cda-148b-40cc-a093-268b6d23778e","nodeType":"const"}}}}},"cell_type":"code","id":"765bd430-d730-47df-970a-802b01f40c96","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"dataset","type":"string"},{"name":"DS","type":"number"},{"name":"DT(max_depth=1)","type":"number"},{"name":"DT","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2],"dataset":["auto-mpg","autos","hungarian-heart-disease"],"DS":[0.3292517007,0.3283636364,0.4904761905],"DT(max_depth=1)":[0.569484127,0.241048285,0.7708146287],"DT":[0.6567482993,0.5278840049,0.5959508723]}},"total_rows":3,"truncation_type":null},"text/plain":"                   dataset        DS  DT(max_depth=1)        DT\n0                 auto-mpg  0.329252         0.569484  0.656748\n1                    autos  0.328364         0.241048  0.527884\n2  hungarian-heart-disease  0.490476         0.770815  0.595951","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>DS</th>\n      <th>DT(max_depth=1)</th>\n      <th>DT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>auto-mpg</td>\n      <td>0.329252</td>\n      <td>0.569484</td>\n      <td>0.656748</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autos</td>\n      <td>0.328364</td>\n      <td>0.241048</td>\n      <td>0.527884</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hungarian-heart-disease</td>\n      <td>0.490476</td>\n      <td>0.770815</td>\n      <td>0.595951</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":22}],"execution_count":22}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}